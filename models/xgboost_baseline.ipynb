{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# models\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from xgboost import train\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# evaluation file\n",
    "from src.evaluation import label_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Use config {'device': 'cpu', 'seed': False, 'data': {'path': '../data/', 'train_file': 'train.csv', 'test_file': 'test.csv'}, 'preprocessing': {'scale': True, 'fill_missing_dates': True}}\n",
      "INFO:__main__:Use previously generated file ../data//data_export_train.csv_test.csv_fmd-True_s-True.p. Can not redo preprocessing by loading from generated file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2649242, 6)\n",
      "(139438, 6)\n",
      "(2345211, 5)\n"
     ]
    }
   ],
   "source": [
    "%run ../src/DataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SET_SIZE = 0.2\n",
    "RANDOM_SEED = 999\n",
    "SPLITS = 10\n",
    "THRESHOLD = 0.26\n",
    "\n",
    "result_file = 'predict.csv'\n",
    "truth_file = 'ground_truth.hdf'\n",
    "delay = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = [ma for ma in range(5, 105, 5)]\n",
    "\n",
    "for ma in mas:\n",
    "    dl.train[f'MA{ma}'] = dl.train.groupby('kpi_id')['value'].transform(lambda x: x.rolling(window=ma, min_periods=1).mean())\n",
    "    dl.train[f'DIFF_MA{ma}'] = abs(dl.train[f'MA{ma}'] - dl.train['value'])\n",
    "    \n",
    "    dl.val[f'MA{ma}'] = dl.val.groupby('kpi_id')['value'].transform(lambda x: x.rolling(window=ma, min_periods=1).mean())\n",
    "    dl.val[f'DIFF_MA{ma}'] = abs(dl.val[f'MA{ma}'] - dl.val['value'])\n",
    "\n",
    "    dl.test[f'MA{ma}'] = dl.test.groupby('kpi_id')['value'].transform(lambda x: x.rolling(window=ma, min_periods=1).mean())\n",
    "    dl.test[f'DIFF_MA{ma}'] = abs(dl.test[f'MA{ma}'] - dl.test['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ignored = ['timestamp', 'datetime', 'kpi_id', 'label']\n",
    "X_train, y_train = dl.train.loc[:, [c for c in dl.train.columns if c not in c_ignored]], dl.train.loc[:, 'label']\n",
    "X_val, y_val = dl.val.loc[:, [c for c in dl.val.columns if c not in c_ignored]], dl.val.loc[:, 'label']\n",
    "X_test = dl.test.loc[:, [c for c in dl.test.columns if c not in c_ignored]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-auc:0.95717\n",
      "[1]\tvalid-auc:0.96146\n",
      "[2]\tvalid-auc:0.95988\n",
      "[3]\tvalid-auc:0.95984\n",
      "[4]\tvalid-auc:0.96295\n",
      "[5]\tvalid-auc:0.96283\n",
      "[6]\tvalid-auc:0.96477\n",
      "[7]\tvalid-auc:0.96359\n",
      "[8]\tvalid-auc:0.96620\n",
      "[9]\tvalid-auc:0.96681\n",
      "[10]\tvalid-auc:0.96852\n",
      "[11]\tvalid-auc:0.96824\n",
      "[12]\tvalid-auc:0.96809\n",
      "[13]\tvalid-auc:0.96798\n",
      "[14]\tvalid-auc:0.96798\n",
      "[15]\tvalid-auc:0.96797\n"
     ]
    }
   ],
   "source": [
    "dtrain = DMatrix(X_train, label=y_train)\n",
    "dvalid = DMatrix(X_val, label=y_val)\n",
    "watchlist = [(dvalid, 'valid')]\n",
    "params = {\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 200, \n",
    "    'colsample_bytree': 0.8, \n",
    "    'subsample': 0.8, \n",
    "    'eta': 0.04,    \n",
    "    'seed': RANDOM_SEED,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "booster = train(params, dtrain, num_boost_round=20, evals=watchlist, early_stopping_rounds=5, verbose_eval=True)\n",
    "best_features = pd.DataFrame(booster.get_score(importance_type='gain').items(), columns=['features', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 30,\n",
    "    'min_child_weight': 200,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.04,\n",
    "    'objective': 'binary:logistic',\n",
    "    'use_label_encoder': False,\n",
    "    'seed': RANDOM_SEED\n",
    "}\n",
    "\n",
    "model = XGBClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David Pissarra\\anaconda3\\envs\\THU\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\David Pissarra\\anaconda3\\envs\\THU\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.95459\n",
      "[1]\tvalidation_0-auc:0.91085\tvalidation_1-auc:0.95864\n",
      "[2]\tvalidation_0-auc:0.90550\tvalidation_1-auc:0.96146\n",
      "[3]\tvalidation_0-auc:0.90511\tvalidation_1-auc:0.96024\n",
      "[4]\tvalidation_0-auc:0.90687\tvalidation_1-auc:0.96176\n",
      "[5]\tvalidation_0-auc:0.90740\tvalidation_1-auc:0.96177\n",
      "[6]\tvalidation_0-auc:0.90995\tvalidation_1-auc:0.96395\n",
      "[7]\tvalidation_0-auc:0.91328\tvalidation_1-auc:0.96379\n",
      "[8]\tvalidation_0-auc:0.91526\tvalidation_1-auc:0.96432\n",
      "[9]\tvalidation_0-auc:0.91615\tvalidation_1-auc:0.96592\n",
      "[10]\tvalidation_0-auc:0.91725\tvalidation_1-auc:0.96687\n",
      "[11]\tvalidation_0-auc:0.91671\tvalidation_1-auc:0.96676\n",
      "[12]\tvalidation_0-auc:0.91710\tvalidation_1-auc:0.96752\n",
      "[13]\tvalidation_0-auc:0.91671\tvalidation_1-auc:0.96752\n",
      "[14]\tvalidation_0-auc:0.91755\tvalidation_1-auc:0.96726\n",
      "[15]\tvalidation_0-auc:0.92050\tvalidation_1-auc:0.96973\n",
      "[16]\tvalidation_0-auc:0.91826\tvalidation_1-auc:0.96909\n",
      "[17]\tvalidation_0-auc:0.92117\tvalidation_1-auc:0.97008\n",
      "[18]\tvalidation_0-auc:0.92163\tvalidation_1-auc:0.97070\n",
      "[19]\tvalidation_0-auc:0.92222\tvalidation_1-auc:0.97104\n",
      "[20]\tvalidation_0-auc:0.92219\tvalidation_1-auc:0.97090\n",
      "[21]\tvalidation_0-auc:0.92261\tvalidation_1-auc:0.97081\n",
      "[22]\tvalidation_0-auc:0.92408\tvalidation_1-auc:0.97132\n",
      "[23]\tvalidation_0-auc:0.92452\tvalidation_1-auc:0.97130\n",
      "[24]\tvalidation_0-auc:0.92559\tvalidation_1-auc:0.97163\n",
      "[25]\tvalidation_0-auc:0.92965\tvalidation_1-auc:0.97254\n",
      "[26]\tvalidation_0-auc:0.92943\tvalidation_1-auc:0.97230\n",
      "[27]\tvalidation_0-auc:0.92938\tvalidation_1-auc:0.97222\n",
      "[28]\tvalidation_0-auc:0.92936\tvalidation_1-auc:0.97203\n",
      "[29]\tvalidation_0-auc:0.92939\tvalidation_1-auc:0.97207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False, eta=0.04,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.0399999991, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=7, max_leaves=0, min_child_weight=200,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=30, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=999,\n",
       "              reg_alpha=0, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': 'auc',\n",
    "    'eval_set': [(X_train, y_train), (X_val, y_val)],\n",
    "    'early_stopping_rounds': 5,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "model.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": true, \"data\": 0.5910519667459827, \"message\": \"计算成功\"}\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(X_train)[:,1]\n",
    "pred = np.where(pred > THRESHOLD, 1, 0)\n",
    "prediction = dl.train.loc[:, ['timestamp', 'kpi_id']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "prediction['predict'] = pred\n",
    "prediction.to_csv(result_file)\n",
    "\n",
    "ground_truth = dl.train.loc[:, ['timestamp', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "ground_truth.to_hdf(truth_file, key='df')\n",
    "\n",
    "print(label_evaluation(truth_file, result_file, delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": true, \"data\": 0.9149949849548645, \"message\": \"计算成功\"}\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(X_val)[:,1]\n",
    "pred = np.where(pred > THRESHOLD, 1, 0)\n",
    "prediction = dl.val.loc[:, ['timestamp', 'kpi_id']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "prediction['predict'] = pred\n",
    "prediction.to_csv(result_file)\n",
    "\n",
    "ground_truth = dl.val.loc[:, ['timestamp', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "ground_truth.to_hdf(truth_file, key='df')\n",
    "\n",
    "print(label_evaluation(truth_file, result_file, delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(X_test)[:,1]\n",
    "pred = np.where(pred > THRESHOLD, 1, 0)\n",
    "prediction = dl.test.loc[:, ['timestamp', 'kpi_id']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "prediction['predict'] = pred\n",
    "prediction.to_csv(result_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d4133a6686e7b6e1653cde6574acd837d64e50b91f09c2e2fee9163e88bab39"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('THU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
