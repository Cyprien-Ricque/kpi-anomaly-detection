{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from evaluation import label_evaluation\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = '../'\n",
    "\n",
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "train_path = data_folder + train_file\n",
    "test_path = data_folder + test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2476315, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    timestamp     value  label            kpi_id\n0  1493568000  1.901639      0  02e99bd4f6cfb33f\n1  1493568060  1.786885      0  02e99bd4f6cfb33f",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>value</th>\n      <th>label</th>\n      <th>kpi_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1493568000</td>\n      <td>1.901639</td>\n      <td>0</td>\n      <td>02e99bd4f6cfb33f</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1493568060</td>\n      <td>1.786885</td>\n      <td>0</td>\n      <td>02e99bd4f6cfb33f</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path).rename(columns={'KPI ID': 'kpi_id'})\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train['datetime'] = pd.to_datetime(df_train.timestamp, unit='s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate test evaluation files\n",
    "\n",
    "to run : ```python evaluation.py 'ground_truth.hdf' 'predict.csv' 7```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance Metric\n",
    "\n",
    "The anomaly detection algorithm need to give a predicted label (0 or 1) for every observation in testing set. We use F-score on test set as the final performance metric in the ranking.\n",
    "In real applications, the human operators generally do not care about the point-wise metrics. It is acceptable for an algorithm to trigger an alert for any point in a contiguous anomaly segment if the delay is not too long.\n",
    "**For an anomaly segment with start point i, if any points between *i* to *T+i* in the ground truth were detected, we say this segment is detected correctly, and all points in this segment are treated as true positives. Otherwise, all points in this segment are regarded as false negatives**. Meanwhile, the points outside the anomaly segments are treated as usual. For example (see the figure below), when *T=1*, the first anomaly segment was detected and the second segment\n",
    "was not, so the precision=0.75, recall=0.5. Based on the above strategy, we calculate F-score.\n",
    "\n",
    "<img src=\"./assets/evaluation.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "result_file = 'predict.csv'\n",
    "truth_file = 'ground_truth.hdf'\n",
    "delay = 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prefect Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "predict = df_train.loc[:, ['timestamp', 'value', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID', 'label': 'predict'})\n",
    "predict.to_csv(result_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "ground_truth = df_train.loc[:, ['timestamp', 'value', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "ground_truth.to_hdf(truth_file, key='df')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": true, \"data\": 1.0, \"message\": \"计算成功\"}\n"
     ]
    }
   ],
   "source": [
    "print(label_evaluation(truth_file, result_file, delay))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "predict = df_train.loc[:, ['timestamp', 'value', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID', 'label': 'predict'})\n",
    "predict.predict = np.random.choice([0, 1], predict.predict.shape)\n",
    "predict.to_csv(result_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "ground_truth = df_train.loc[:, ['timestamp', 'value', 'kpi_id', 'label']].rename(columns={'kpi_id': 'KPI ID'})\n",
    "ground_truth.to_hdf(truth_file, key='df')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": true, \"data\": 0.0808301076509794, \"message\": \"计算成功\"}\n"
     ]
    }
   ],
   "source": [
    "print(label_evaluation(truth_file, result_file, delay))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}